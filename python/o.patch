--- mnist-backup.py	2017-09-12 09:25:48.490271200 -0400
+++ mnist.py	2017-09-13 13:25:37.277130600 -0400
@@ -17,6 +17,8 @@
 import sys
 import os
 import time
+import gc
+import psutil
 
 import numpy as np
 import theano
@@ -294,7 +296,7 @@
         train_err = 0
         train_batches = 0
         start_time = time.time()
-        for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):
+        for batch in iterate_minibatches(X_train, y_train, 32, shuffle=True):
             inputs, targets = batch
             train_err += train_fn(inputs, targets)
             train_batches += 1
@@ -317,6 +319,11 @@
         print("  validation loss:\t\t{:.6f}".format(val_err / val_batches))
         print("  validation accuracy:\t\t{:.2f} %".format(
             val_acc / val_batches * 100))
+        while gc.collect() > 0:
+            pass
+        print('  memory use:\t\t\t{:.3f} MiB'.format(
+            psutil.Process().memory_info()[0] / float(1024**2)))
+
 
     # After training, we compute and print the test error:
     test_err = 0
@@ -332,6 +339,10 @@
     print("  test loss:\t\t\t{:.6f}".format(test_err / test_batches))
     print("  test accuracy:\t\t{:.2f} %".format(
         test_acc / test_batches * 100))
+    while gc.collect() > 0:
+        pass
+    print('  memory use:\t\t\t{:.3f} MiB'.format(
+        psutil.Process().memory_info()[0] / float(1024**2)))
 
     # Optionally, you could now dump the network weights to a file like this:
     # np.savez('model.npz', *lasagne.layers.get_all_param_values(network))
