Highlights
 - Moved Python 3.* minimum supported version from 3.3 to 3.4
 - Replaced deprecated package ``nose-parameterized`` with up-to-date package ``parameterized`` for Theano requirements
 - Removed old GPU backend ``theano.sandbox.cuda``. New backend ``theano.gpuarray`` is now the official GPU backend
 - Support more debuggers for ``PdbBreakpoint``
 - Faster compilation step by massively using a new interface for op params
 - Faster optimization step
 - Documentation updated and more complete
 - Many bug fixes, crash fixes and warning improvements

New features
 - Added a wrapper for baidu's CTC cost and gradient functions
 - Implemented separable convolutions
 - Implemented grouped convolutions
 - Added Scaled Exponential Linear Unit (SELU) activation
 - Added sigmoid_binary_crossentropy function
 - Added tri-gamma function
 - Added modes ``half`` and ``full`` for ``Images2Neibs`` ops
 - Implemented gradient for ``AbstractBatchNormTrainGrad``
 - Implemented gradient for matrix pseudoinverse op
 - Added new prop `replace` for ``ChoiceFromUniform`` op
 - Added new prop ``on_error`` for CPU ``Cholesky`` op
 - Added new theano flag ``cmodule.debug`` to create a debug mode for theano C code.
 - Added new theano flag ``deterministic`` to help control how Theano optimize certain ops that have deterministic versions. Currently used for subtensor Ops only.
 - Added new theano flag ``cycle_detection`` that allows to speed-up compilation step by reducing time spending in inplace optimization step.
 - Added new theano flag ``check_stack_trace`` to help check the stack trace during optimization process.

Interface changes
 - Replaced ``MultinomialWOReplacementFromUniform`` with ``ChoiceFromUniform``

cuDNN
 - Official support for versions ``>=`` ``v5.1``
 - Better support and loading on Windows and Mac
 - Added support for cuDNN v6 dilated convolutions
 - Support cuDNN reductions for ``v6.0`` and later

GPU
 - Prevent GPU initialization when not required
 - Added useful stats for GPU in profile mode
 - Added disk caching option for new backend kernels
 - Added Cholesky op based on ``cusolver`` backend
 - Added GPU ops based on magma library: SVD, matrix inverse, QR, cholesky and eigh
 - Added GpuAdvancedIncSubtensor
 - Added GpuCublasTriangularSolve
 - Added atomic addition and exchange for ``long long`` values in ``GpuAdvancedIncSubtensor1_dev20``
 - Fixed C code for log gamma function, now supporting all types except complex types.
 - Support GPU SoftMax in both OpenCL and CUDA
 - Support offset parameter ``k`` for ``GpuEye``
 - ``CrossentropyCategorical1Hot`` and its gradient are now lifted to GPU

 - ``float16`` support
   - Added documentation for GPU float16 ops
   - Support ``float16`` for ``GpuGemmBatch``
   - Started to avoid lifting ``float16`` computations that are not supported on GPU

Other changes
 - Added deprecation warning for the softmax and logsoftmax vector case

Other more detailed changes:
 - Removed ``theano/compat/six.py``
 - Removed ``COp.get_op_params()``
 - Support of list of strings for ``Op.c_support_code()``, to help not duplicate support codes
 - Added options for `disconnected_outputs` to Rop
 - Macro names provided for tensor properties are now standardized in both CPU and GPU C codes
 - Insertion of an OutputGuard is now considered as an error
 - Started to move C code files into separate folder ``c_code`` in every Theano module
 - Many improvements for TRAVIS CI tests (with better splitting for faster testing)
 - Many improvements for Jenkins CI tests: support for Mac and Windows testings, usage of Docker for better tests isolation

